//#define PROCESS_MASK

#include "NeuralSlamDR.h"

using namespace std;

namespace NeuralSlamDR
{
    NSDSystem::NSDSystem(const string& vocabFile, const string& calibrationFile)
    {
        SLAM = new ORB_SLAM2::System(vocabFile,calibrationFile,ORB_SLAM2::System::MONOCULAR,true); //vocab yaml mono true
        cout << "PLANEPOS = "<< endl << " "  << planePosition << endl << endl;
    }

    void NSDSystem::UseFileMode(const string& filePath, const string& maskFilePath )
    {
        videoFile.open(filePath);
        //cv::cvSetCaptureProperty(videoFile,cv::CV_CAP_PROP_POS_FRAMES, 2000);
        //videoFile.set(CV_CAP_PROP_POS_MSEC,2000);
        maskFile.open(maskFilePath);
        // Create SLAM system. It initializes all system threads and gets ready to process frames.
    }

    void NSDSystem::UseCameraMode()
    {
        webcam.open(0);

        if( !webcam.isOpened() )
        {
            std::cerr << "***Could not initialize capturing...***\n";
            std::cerr << "Current parameter's value: \n";
        }
    }

    void NSDSystem::ProcessFrame()
    {
        if(inputMode == FILE)
        {
            //argv[4] should be real video, and argv[5] should be the human mask video
            videoFile>>im;

            #ifdef PROCESS_MASK
            maskFile>>mask;

            if(!im.data || !mask.data)
            {
                break;
            }
            #endif
        }
        else
        {
            // im is from live camera
            webcam >> im;
            //TODO: get the mask out of im
            //TODO: how to run python from here?
        }


        /*
        #ifdef COMPILEDWITHC11
        std::chrono::steady_clock::time_point t1 = std::chrono::steady_clock::now();
        #else
        std::chrono::monotonic_clock::time_point t1 = std::chrono::monotonic_clock::now();
        #endif
        */

        // Pass the image to the SLAM system
        SLAM->TrackMonocular(im,0); //lets look later how the system uses that "timestamp"
        // this function create new Mat which I did not freed.
        // in the long run this might cause big memory leaks?
        //cameraPose = SLAM->GetCurrentCameraMatrix();

        //string ty =  type2str( cameraPose.type() );
        //printf("Matrix: %s %dx%d \n", ty.c_str(), cameraPose.cols, cameraPose.rows );


    //TODO : Store camera pose and position. Store all the colors of that pose into plane. Masked pixels does not count.

    //TODO : For current image, attempt to replace masked pixels with something else. Try to interpolate colors from the plane if found color data.
    //cout << "3333";

/*
    cv::Mat resized;
    cv::resize(plane,resized,cv::Size(500,500));

    //displaying result
    SLAM->FeedAuxDisplay(resized);
    SLAM->FeedOutputDisplay(output);
    #endif //end of PROCESS_MASK

    //usleep((1/(float)90)*1e6); //the wait

    #ifdef PROCESS_MASK
    std::clog << std::flush ;
    std::clog.rdbuf( old_clog_buf ) ;
    */

    }

}

int main(int argc, char **argv)
{
    bool fileMode = false;
    if(std::string(argv[3]) == "FILE")
    {
        if(argc != 6)
        {
            std::cerr << "Format : vocab calibration FILE file maskfile\n";
            return 0;
        }
        fileMode = true;
    }
    else if (std::string(argv[3]) == "CAMERA")
    {
        fileMode = false;
    }
    else
    {
    // Create SLAM system. It initializes all system threads and gets ready to process frames.
    ORB_SLAM2::System SLAM(argv[1],argv[2],ORB_SLAM2::System::MONOCULAR,true); //vocab yaml mono true
        std::cerr << "Format : vocab calibration FILE/CAMERA [file] [maskfile]\n";
        return 0;
    }

    NeuralSlamDR::NSDSystem nsd(argv[1],argv[2]);
    if(fileMode == false)
    {
        nsd.UseCameraMode();
    }
    else
    {
        nsd.UseFileMode(argv[4],argv[5]);
    }

    while(1)
    {
        nsd.ProcessFrame();
    }

// Stop all threads
//SLAM.Shutdown();

/*
// Tracking time statistics
sort(vTimesTrack.begin(),vTimesTrack.end());
float totaltime = 0;
for(int ni=0; ni<nImages; ni++)
{
totaltime+=vTimesTrack[ni];
}
cout << "-------" << endl << endl;
cout << "median tracking time: " << vTimesTrack[nImages/2] << endl;
cout << "mean tracking time: " << totaltime/nImages << endl;

// Save camera trajectory
SLAM.SaveKeyFrameTrajectoryTUM("KeyFrameTrajectory.txt");
*/

cout << "End of program!" << endl << endl;
return 0;
}
